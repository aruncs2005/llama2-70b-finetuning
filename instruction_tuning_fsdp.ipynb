{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune llama 2 70b on prompts using Pytorch FSDP and Amazon SageMaker Training Jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (2.188.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.189.0.tar.gz (893 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (1.28.57)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.28.59-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs<24,>=23.1.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (1.24.2)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (22.0)\n",
      "Requirement already satisfied: pandas in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: pathos in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Collecting botocore<1.32.0,>=1.31.59 (from boto3)\n",
      "  Downloading botocore-1.31.59-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from boto3) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.59->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.59->boto3) (1.26.15)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.15.0)\n",
      "Requirement already satisfied: six in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.189.0-py2.py3-none-any.whl size=1194917 sha256=a848a11efeeccd3ce8d7e57f41d66b0f0a547907c31f8374d562a83402150ca2\n",
      "  Stored in directory: /Users/alokana/Library/Caches/pip/wheels/98/11/11/0ed146622a4b4485d9f3c5454fb42f07895c69b6d1d1516987\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: botocore, boto3, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.57\n",
      "    Uninstalling botocore-1.31.57:\n",
      "      Successfully uninstalled botocore-1.31.57\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.28.57\n",
      "    Uninstalling boto3-1.28.57:\n",
      "      Successfully uninstalled boto3-1.28.57\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.188.0\n",
      "    Uninstalling sagemaker-2.188.0:\n",
      "      Successfully uninstalled sagemaker-2.188.0\n",
      "Successfully installed boto3-1.28.59 botocore-1.31.59 sagemaker-2.189.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -U sagemaker boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/alokana/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/alokana/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/alokana/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/alokana/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::365792799466:role/test_step_role\n",
      "sagemaker bucket: sagemaker-us-west-2-365792799466\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokana/Documents/projects/pathways/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset hc3 (/Users/alokana/.cache/huggingface/datasets/Hello-SimpleAI___hc3/all/1.1.0/5af5910f9f3fe7aace30e32ad4c1ab776ca08183d00e9b2a091308549f69f683)\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.99it/s]\n",
      "Creating json from Arrow format: 100%|██████████| 25/25 [00:00<00:00, 35.40ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73742573"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hc3 = load_dataset(\"Hello-SimpleAI/HC3\",\"all\")\n",
    "hc3[\"train\"].to_json(f\"data/all.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in training set 24322\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f1 = open('data/all.jsonl')\n",
    "Lines1 = f1.readlines()\n",
    "\n",
    "questions, answers = [], []\n",
    "print(f\"Total lines in training set {len(Lines1)}\")\n",
    "for line in Lines1[:10000]:\n",
    "    row = json.loads(line)\n",
    "    for answer in row[\"human_answers\"]:\n",
    "        questions.append(row[\"question\"])\n",
    "        answers.append(answer)\n",
    "    for answer in row[\"chatgpt_answers\"]:\n",
    "        questions.append(row[\"question\"])\n",
    "        answers.append(answer)\n",
    "\n",
    "test_file = open(\"data/test.jsonl\",\"w\")\n",
    "for line in Lines1[10000:]:\n",
    "    test_file.write(line)\n",
    "\n",
    "test_file.close()\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[\"question\"] = questions\n",
    "df[\"answer\"] = answers\n",
    "df = df.sample(frac = 1)\n",
    "df_train = df.iloc[:30000,:]\n",
    "df_val = df.iloc[30000:40000,:]\n",
    "\n",
    "df_train.to_csv(\"data/train.csv\", index=False)\n",
    "df_val.to_csv(\"data/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_url = sess.upload_data(\n",
    "    path=\"data/train.csv\",\n",
    "    key_prefix=\"alpaca/prompt\",\n",
    ")\n",
    "\n",
    "valid_data_url = sess.upload_data(\n",
    "    path=\"data/val.csv\",\n",
    "    key_prefix=\"alpaca/prompt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file path s3://sagemaker-us-west-2-365792799466/alpaca/prompt/train.csv\n",
      "validation file path s3://sagemaker-us-west-2-365792799466/alpaca/prompt/val.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"training file path {train_data_url}\")\n",
    "print(f\"validation file path {valid_data_url}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit training job to SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "SM_TRAIN_DIR = \"/opt/ml/input/data\" \n",
    "\n",
    "hyperparameters[\"model_name_or_path\"] = \"meta-llama/Llama-2-70b-hf\"\n",
    "hyperparameters[\"model_dir\"] =  \"/opt/ml/model\"\n",
    "hyperparameters[\"train_file\"] = f\"{SM_TRAIN_DIR}/train/train.csv\"\n",
    "hyperparameters[\"validation_file\"] = f\"{SM_TRAIN_DIR}/valid/val.csv\"\n",
    "hyperparameters[\"per_device_train_batch_size\"] = 1\n",
    "hyperparameters[\"per_device_eval_batch_size\"] = 1\n",
    "hyperparameters[\"block_size\"] = 4096\n",
    "hyperparameters[\"num_train_epochs\"] = 1\n",
    "hyperparameters[\"learning_rate\"] = 2e-4\n",
    "hyperparameters[\"transformer_layer_cls_to_wrap\"] = \"LlamaDecoderLayer\" # provide the decoder layer\n",
    "hyperparameters[\"access_token\"] = \"hf_XXXXXX\"\n",
    "hyperparameters[\"cache_dir\"] = \"/opt/ml/sagemaker/warmpoolcache\" #change this to /tmp if not using warmpools.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {}\n",
    "env['FI_PROVIDER'] = 'efa'\n",
    "env['NCCL_PROTO'] = 'simple'\n",
    "env['FI_EFA_USE_DEVICE_RDMA'] = '1'\n",
    "env['RDMAV_FORK_SAFE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/alokana/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "base_job_name = \"falcon-instruction-fine-tuning\"\n",
    "estimator = PyTorch(\n",
    "    base_job_name=base_job_name,\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"train_fsdp.py\",\n",
    "    role=role,\n",
    "    framework_version=\"2.0.1\",\n",
    "    py_version=\"py310\",\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.p4de.24xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    disable_profiler=True,\n",
    "    environment=env,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    keep_alive_period_in_seconds=600, \n",
    "    disable_output_compression=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: falcon-instruction-fine-tuning-2023-10-03-20-09-40-599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-10-03 20:09:42 Starting - Starting the training job\n",
      "2023-10-03 20:09:42 Pending - Training job waiting for capacity......\n",
      "2023-10-03 20:10:33 Pending - Preparing the instances for training........................\n",
      "2023-10-03 20:14:37 Downloading - Downloading input data...\n",
      "2023-10-03 20:15:02 Training - Downloading the training image........................\n",
      "2023-10-03 20:19:24 Training - Training image download completed. Training in progress........bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2023-10-03 20:20:20,506 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2023-10-03 20:20:20,561 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:20,569 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2023-10-03 20:20:20,570 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\n",
      "2023-10-03 20:20:20,570 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2023-10-03 20:20:21,944 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.10 -m pip install -r requirements.txt\n",
      "Collecting transformers>=4.31.0 (from -r requirements.txt (line 1))\n",
      "Obtaining dependency information for transformers>=4.31.0 from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\n",
      "Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.5/121.5 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.22.0)\n",
      "Collecting datasets (from -r requirements.txt (line 3))\n",
      "Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\n",
      "Downloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tensorboard (from -r requirements.txt (line 4))\n",
      "Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/73/a2/66ed644f6ed1562e0285fcd959af17670ea313c8f331c46f79ee77187eb9/tensorboard-2.14.1-py3-none-any.whl.metadata\n",
      "Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting sentencepiece (from -r requirements.txt (line 5))\n",
      "Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 10.5 MB/s eta 0:00:00\n",
      "Collecting optimum (from -r requirements.txt (line 6))\n",
      "Downloading optimum-1.13.2.tar.gz (300 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.0/301.0 kB 12.5 MB/s eta 0:00:00\n",
      "Installing build dependencies: started\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2023-10-03 20:20:21,512 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2023-10-03 20:20:21,569 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:21,576 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2023-10-03 20:20:21,578 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\n",
      "2023-10-03 20:20:21,578 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2023-10-03 20:20:22,886 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.10 -m pip install -r requirements.txt\n",
      "Collecting transformers>=4.31.0 (from -r requirements.txt (line 1))\n",
      "Obtaining dependency information for transformers>=4.31.0 from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\n",
      "Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.5/121.5 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.22.0)\n",
      "Collecting datasets (from -r requirements.txt (line 3))\n",
      "Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\n",
      "Downloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tensorboard (from -r requirements.txt (line 4))\n",
      "Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/73/a2/66ed644f6ed1562e0285fcd959af17670ea313c8f331c46f79ee77187eb9/tensorboard-2.14.1-py3-none-any.whl.metadata\n",
      "Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting sentencepiece (from -r requirements.txt (line 5))\n",
      "Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 34.4 MB/s eta 0:00:00\n",
      "Collecting optimum (from -r requirements.txt (line 6))\n",
      "Downloading optimum-1.13.2.tar.gz (300 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.0/301.0 kB 54.4 MB/s eta 0:00:00\n",
      "Installing build dependencies: started\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting peft (from -r requirements.txt (line 7))\n",
      "Obtaining dependency information for peft from https://files.pythonhosted.org/packages/37/1a/8d20e8704da9fa070eb909265584b960da57be1d833d550c59f50906dc5c/peft-0.5.0-py3-none-any.whl.metadata\n",
      "Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (3.12.4)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Installing build dependencies: finished with status 'done'\n",
      "Getting requirements to build wheel: started\n",
      "Getting requirements to build wheel: finished with status 'done'\n",
      "Preparing metadata (pyproject.toml): started\n",
      "Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting peft (from -r requirements.txt (line 7))\n",
      "Obtaining dependency information for peft from https://files.pythonhosted.org/packages/37/1a/8d20e8704da9fa070eb909265584b960da57be1d833d550c59f50906dc5c/peft-0.5.0-py3-none-any.whl.metadata\n",
      "Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/57/bd/45b5ef6b088880779f70acf60027f7043ca5fa1b98f4a4345cf3aea09044/tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (3.12.4)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 13.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/13/c3/e942893f4864a424514c81640f114980cfd5aff7e7414d1e0255f4571111/xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.15)\n",
      "Collecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for fsspec[http]<2023.9.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting aiohttp (from datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/3e/f6/fcda07dd1e72260989f0b22dde999ecfe80daa744f23ca167083683399bc/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/57/bd/45b5ef6b088880779f70acf60027f7043ca5fa1b98f4a4345cf3aea09044/tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->-r requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 2)) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (2.1.1)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/13/c3/e942893f4864a424514c81640f114980cfd5aff7e7414d1e0255f4571111/xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.15)\n",
      "Collecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for fsspec[http]<2023.9.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting aiohttp (from datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/3e/f6/fcda07dd1e72260989f0b22dde999ecfe80daa744f23ca167083683399bc/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/20/7f/e76618521aa9d33c6c1c9c3473f866da521678aa6ea2f4df3a896757748c/grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/d7/88/1826b0c047c48763b36ed854a984127b430a16b70003155d7b19975f1d59/google_auth-2.23.2-py2.py3-none-any.whl.metadata\n",
      "Downloading google_auth-2.23.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard->-r requirements.txt (line 4))\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/1a/b5/228c1cdcfe138f1a8e01ab1b54284c8b83735476cb22b6ba251656ed13ad/Markdown-3.4.4-py3-none-any.whl.metadata\n",
      "Downloading Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (65.6.3)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/02/52/fb9e51fba47951aabd7a6b25e41d73eae94208ccf62d886168096941a781/tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (2.3.7)\n",
      "Collecting coloredlogs (from optimum->-r requirements.txt (line 6))\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 10.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum->-r requirements.txt (line 6)) (1.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 13.8 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/20/7f/e76618521aa9d33c6c1c9c3473f866da521678aa6ea2f4df3a896757748c/grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/d7/88/1826b0c047c48763b36ed854a984127b430a16b70003155d7b19975f1d59/google_auth-2.23.2-py2.py3-none-any.whl.metadata\n",
      "Downloading google_auth-2.23.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard->-r requirements.txt (line 4))\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/1a/b5/228c1cdcfe138f1a8e01ab1b54284c8b83735476cb22b6ba251656ed13ad/Markdown-3.4.4-py3-none-any.whl.metadata\n",
      "Downloading Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (65.6.3)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/02/52/fb9e51fba47951aabd7a6b25e41d73eae94208ccf62d886168096941a781/tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 4)) (2.3.7)\n",
      "Collecting coloredlogs (from optimum->-r requirements.txt (line 6))\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 12.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum->-r requirements.txt (line 6)) (1.12)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 14.7 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/1e/28/74b8b6451c89c070d34e753d8b65a1e4ce508a6808b18529f36e8c0e2184/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4))\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 14.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4)) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 4))\n",
      "Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.31.0->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 1)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 4)) (2.1.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum->-r requirements.txt (line 6))\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 16.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (3.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 31.0 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 56.5 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/1e/28/74b8b6451c89c070d34e753d8b65a1e4ce508a6808b18529f36e8c0e2184/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 3))\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4))\n",
      "Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4))\n",
      "Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 45.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4)) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 4))\n",
      "Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.31.0->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 1)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 4))\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 30.2 MB/s eta 0:00:00\n",
      "Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 519.6/519.6 kB 49.7 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 46.3 MB/s eta 0:00:00\n",
      "Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 22.0 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.2/130.2 kB 26.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 55.4 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.23.2-py2.py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 182.0/182.0 kB 41.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 57.5 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 24.4 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 773.9/773.9 kB 61.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 59.8 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 77.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.31.0->-r requirements.txt (line 1))\n",
      "Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 4)) (2.1.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum->-r requirements.txt (line 6))\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 21.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 4)) (0.5.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 4))\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 39.5 MB/s eta 0:00:00\n",
      "Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 104.4 MB/s eta 0:00:00\n",
      "Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 519.6/519.6 kB 71.2 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 101.6 MB/s eta 0:00:00\n",
      "Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 20.7 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.2/130.2 kB 36.3 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 74.8 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.23.2-py2.py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 182.0/182.0 kB 42.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 93.1 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.2/94.2 kB 26.5 MB/s eta 0:00:00\n",
      "Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 773.9/773.9 kB 82.9 MB/s eta 0:00:00\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 86.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 48.3 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 37.5 MB/s eta 0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.7/225.7 kB 41.9 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 31.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: optimum\n",
      "Building wheel for optimum (pyproject.toml): started\n",
      "Building wheel for optimum (pyproject.toml): finished with status 'done'\n",
      "Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=8b0229f03d830e4a4b5cb501acdd6ef75f016612d275a273b1a00fb09c7c1af4\n",
      "Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n",
      "Successfully built optimum\n",
      "Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 98.8 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 85.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 113.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 41.0 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 42.7 MB/s eta 0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.7/225.7 kB 37.3 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 37.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: optimum\n",
      "Building wheel for optimum (pyproject.toml): started\n",
      "Building wheel for optimum (pyproject.toml): finished with status 'done'\n",
      "Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=2063ea164aa8075b6619a2ea6f643181549edb374178c0f3bc3f0c21f1d3a0b8\n",
      "Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n",
      "Successfully built optimum\n",
      "Installing collected packages: sentencepiece, safetensors, xxhash, tensorboard-data-server, regex, pyasn1-modules, oauthlib, multidict, markdown, humanfriendly, grpcio, fsspec, frozenlist, cachetools, async-timeout, absl-py, yarl, requests-oauthlib, huggingface-hub, google-auth, coloredlogs, aiosignal, tokenizers, google-auth-oauthlib, aiohttp, transformers, tensorboard, peft, datasets, optimum\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2023.9.2\n",
      "Uninstalling fsspec-2023.9.2:\n",
      "Successfully uninstalled fsspec-2023.9.2\n",
      "Installing collected packages: sentencepiece, safetensors, xxhash, tensorboard-data-server, regex, pyasn1-modules, oauthlib, multidict, markdown, humanfriendly, grpcio, fsspec, frozenlist, cachetools, async-timeout, absl-py, yarl, requests-oauthlib, huggingface-hub, google-auth, coloredlogs, aiosignal, tokenizers, google-auth-oauthlib, aiohttp, transformers, tensorboard, peft, datasets, optimum\n",
      "Attempting uninstall: fsspec\n",
      "Found existing installation: fsspec 2023.9.2\n",
      "Uninstalling fsspec-2023.9.2:\n",
      "Successfully uninstalled fsspec-2023.9.2\n",
      "Successfully installed absl-py-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 cachetools-5.3.1 coloredlogs-15.0.1 datasets-2.14.5 frozenlist-1.4.0 fsspec-2023.6.0 google-auth-2.23.2 google-auth-oauthlib-1.0.0 grpcio-1.59.0 huggingface-hub-0.16.4 humanfriendly-10.0 markdown-3.4.4 multidict-6.0.4 oauthlib-3.2.2 optimum-1.13.2 peft-0.5.0 pyasn1-modules-0.3.0 regex-2023.10.3 requests-oauthlib-1.3.1 safetensors-0.3.3 sentencepiece-0.1.99 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tokenizers-0.14.0 transformers-4.34.0 xxhash-3.3.0 yarl-1.9.2\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Successfully installed absl-py-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 cachetools-5.3.1 coloredlogs-15.0.1 datasets-2.14.5 frozenlist-1.4.0 fsspec-2023.6.0 google-auth-2.23.2 google-auth-oauthlib-1.0.0 grpcio-1.59.0 huggingface-hub-0.16.4 humanfriendly-10.0 markdown-3.4.4 multidict-6.0.4 oauthlib-3.2.2 optimum-1.13.2 peft-0.5.0 pyasn1-modules-0.3.0 regex-2023.10.3 requests-oauthlib-1.3.1 safetensors-0.3.3 sentencepiece-0.1.99 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tokenizers-0.14.0 transformers-4.34.0 xxhash-3.3.0 yarl-1.9.2\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "2023-10-03 20:20:39,410 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-10-03 20:20:39,411 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2023-10-03 20:20:39,486 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:39,550 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:39,558 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\n",
      "2023-10-03 20:20:39,612 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:39,621 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.p4de.24xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"valid\": \"/opt/ml/input/data/valid\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-2\",\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4de.24xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-2\",\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"access_token\": \"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\",\n",
      "        \"block_size\": 4096,\n",
      "        \"cache_dir\": \"/opt/ml/sagemaker/warmpoolcache\",\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"model_name_or_path\": \"meta-llama/Llama-2-70b-hf\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"per_device_eval_batch_size\": 1,\n",
      "        \"per_device_train_batch_size\": 1,\n",
      "        \"train_file\": \"/opt/ml/input/data/train/train.csv\",\n",
      "        \"transformer_layer_cls_to_wrap\": \"LlamaDecoderLayer\",\n",
      "        \"validation_file\": \"/opt/ml/input/data/valid/val.csv\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4de.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-2\",\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"falcon-instruction-fine-tuning-2023-10-03-20-09-40-599\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-2\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-365792799466/falcon-instruction-fine-tuning-2023-10-03-20-09-40-599/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_fsdp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.p4de.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4de.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_fsdp.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"access_token\":\"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\",\"block_size\":4096,\"cache_dir\":\"/opt/ml/sagemaker/warmpoolcache\",\"learning_rate\":0.0002,\"model_dir\":\"/opt/ml/model\",\"model_name_or_path\":\"meta-llama/Llama-2-70b-hf\",\"num_train_epochs\":1,\"per_device_eval_batch_size\":1,\"per_device_train_batch_size\":1,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"transformer_layer_cls_to_wrap\":\"LlamaDecoderLayer\",\"validation_file\":\"/opt/ml/input/data/valid/val.csv\"}\n",
      "SM_USER_ENTRY_POINT=train_fsdp.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.p4de.24xlarge\",\"sagemaker_torch_distributed_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p4de.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"train\",\"valid\"]\n",
      "SM_CURRENT_HOST=algo-2\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.p4de.24xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-2\",\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train_fsdp\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=96\n",
      "SM_NUM_GPUS=8\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-west-2-365792799466/falcon-instruction-fine-tuning-2023-10-03-20-09-40-599/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p4de.24xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"valid\":\"/opt/ml/input/data/valid\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-2\",\"algo-1\"],\"current_instance_type\":\"ml.p4de.24xlarge\",\"distribution_hosts\":[\"algo-2\",\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"access_token\":\"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\",\"block_size\":4096,\"cache_dir\":\"/opt/ml/sagemaker/warmpoolcache\",\"learning_rate\":0.0002,\"model_dir\":\"/opt/ml/model\",\"model_name_or_path\":\"meta-llama/Llama-2-70b-hf\",\"num_train_epochs\":1,\"per_device_eval_batch_size\":1,\"per_device_train_batch_size\":1,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"transformer_layer_cls_to_wrap\":\"LlamaDecoderLayer\",\"validation_file\":\"/opt/ml/input/data/valid/val.csv\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"falcon-instruction-fine-tuning-2023-10-03-20-09-40-599\",\"log_level\":20,\"master_hostname\":\"algo-2\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-365792799466/falcon-instruction-fine-tuning-2023-10-03-20-09-40-599/source/sourcedir.tar.gz\",\"module_name\":\"train_fsdp\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.p4de.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_fsdp.py\"}\n",
      "SM_USER_ARGS=[\"--access_token\",\"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\",\"--block_size\",\"4096\",\"--cache_dir\",\"/opt/ml/sagemaker/warmpoolcache\",\"--learning_rate\",\"0.0002\",\"--model_dir\",\"/opt/ml/model\",\"--model_name_or_path\",\"meta-llama/Llama-2-70b-hf\",\"--num_train_epochs\",\"1\",\"--per_device_eval_batch_size\",\"1\",\"--per_device_train_batch_size\",\"1\",\"--train_file\",\"/opt/ml/input/data/train/train.csv\",\"--transformer_layer_cls_to_wrap\",\"LlamaDecoderLayer\",\"--validation_file\",\"/opt/ml/input/data/valid/val.csv\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_CHANNEL_VALID=/opt/ml/input/data/valid\n",
      "SM_HP_ACCESS_TOKEN=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\n",
      "SM_HP_BLOCK_SIZE=4096\n",
      "SM_HP_CACHE_DIR=/opt/ml/sagemaker/warmpoolcache\n",
      "SM_HP_LEARNING_RATE=0.0002\n",
      "SM_HP_MODEL_DIR=/opt/ml/model\n",
      "SM_HP_MODEL_NAME_OR_PATH=meta-llama/Llama-2-70b-hf\n",
      "SM_HP_NUM_TRAIN_EPOCHS=1\n",
      "SM_HP_PER_DEVICE_EVAL_BATCH_SIZE=1\n",
      "SM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\n",
      "SM_HP_TRAIN_FILE=/opt/ml/input/data/train/train.csv\n",
      "SM_HP_TRANSFORMER_LAYER_CLS_TO_WRAP=LlamaDecoderLayer\n",
      "SM_HP_VALIDATION_FILE=/opt/ml/input/data/valid/val.csv\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "torchrun --nnodes 2 --nproc_per_node 8 --master_addr algo-2 --master_port 7777 --node_rank 0 train_fsdp.py --access_token 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 --block_size 4096 --cache_dir /opt/ml/sagemaker/warmpoolcache --learning_rate 0.0002 --model_dir /opt/ml/model --model_name_or_path meta-llama/Llama-2-70b-hf --num_train_epochs 1 --per_device_eval_batch_size 1 --per_device_train_batch_size 1 --train_file /opt/ml/input/data/train/train.csv --transformer_layer_cls_to_wrap LlamaDecoderLayer --validation_file /opt/ml/input/data/valid/val.csv\n",
      "2023-10-03 20:20:39,900 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-10-03 20:20:39,900 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2023-10-03 20:20:39,977 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:40,040 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:40,048 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\n",
      "2023-10-03 20:20:40,102 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2023-10-03 20:20:40,110 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.p4de.24xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"valid\": \"/opt/ml/input/data/valid\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-2\",\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4de.24xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-2\",\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"access_token\": \"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\",\n",
      "        \"block_size\": 4096,\n",
      "        \"cache_dir\": \"/opt/ml/sagemaker/warmpoolcache\",\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"model_name_or_path\": \"meta-llama/Llama-2-70b-hf\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"per_device_eval_batch_size\": 1,\n",
      "        \"per_device_train_batch_size\": 1,\n",
      "        \"train_file\": \"/opt/ml/input/data/train/train.csv\",\n",
      "        \"transformer_layer_cls_to_wrap\": \"LlamaDecoderLayer\",\n",
      "        \"validation_file\": \"/opt/ml/input/data/valid/val.csv\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4de.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-2\",\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"falcon-instruction-fine-tuning-2023-10-03-20-09-40-599\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-2\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-365792799466/falcon-instruction-fine-tuning-2023-10-03-20-09-40-599/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_fsdp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4de.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4de.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_fsdp.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"access_token\":\"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\",\"block_size\":4096,\"cache_dir\":\"/opt/ml/sagemaker/warmpoolcache\",\"learning_rate\":0.0002,\"model_dir\":\"/opt/ml/model\",\"model_name_or_path\":\"meta-llama/Llama-2-70b-hf\",\"num_train_epochs\":1,\"per_device_eval_batch_size\":1,\"per_device_train_batch_size\":1,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"transformer_layer_cls_to_wrap\":\"LlamaDecoderLayer\",\"validation_file\":\"/opt/ml/input/data/valid/val.csv\"}\n",
      "SM_USER_ENTRY_POINT=train_fsdp.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.p4de.24xlarge\",\"sagemaker_torch_distributed_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4de.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"train\",\"valid\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.p4de.24xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-2\",\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train_fsdp\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=96\n",
      "SM_NUM_GPUS=8\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-west-2-365792799466/falcon-instruction-fine-tuning-2023-10-03-20-09-40-599/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p4de.24xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"valid\":\"/opt/ml/input/data/valid\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-2\",\"algo-1\"],\"current_instance_type\":\"ml.p4de.24xlarge\",\"distribution_hosts\":[\"algo-2\",\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"access_token\":\"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\",\"block_size\":4096,\"cache_dir\":\"/opt/ml/sagemaker/warmpoolcache\",\"learning_rate\":0.0002,\"model_dir\":\"/opt/ml/model\",\"model_name_or_path\":\"meta-llama/Llama-2-70b-hf\",\"num_train_epochs\":1,\"per_device_eval_batch_size\":1,\"per_device_train_batch_size\":1,\"train_file\":\"/opt/ml/input/data/train/train.csv\",\"transformer_layer_cls_to_wrap\":\"LlamaDecoderLayer\",\"validation_file\":\"/opt/ml/input/data/valid/val.csv\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"valid\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"falcon-instruction-fine-tuning-2023-10-03-20-09-40-599\",\"log_level\":20,\"master_hostname\":\"algo-2\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-365792799466/falcon-instruction-fine-tuning-2023-10-03-20-09-40-599/source/sourcedir.tar.gz\",\"module_name\":\"train_fsdp\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4de.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4de.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_fsdp.py\"}\n",
      "SM_USER_ARGS=[\"--access_token\",\"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\",\"--block_size\",\"4096\",\"--cache_dir\",\"/opt/ml/sagemaker/warmpoolcache\",\"--learning_rate\",\"0.0002\",\"--model_dir\",\"/opt/ml/model\",\"--model_name_or_path\",\"meta-llama/Llama-2-70b-hf\",\"--num_train_epochs\",\"1\",\"--per_device_eval_batch_size\",\"1\",\"--per_device_train_batch_size\",\"1\",\"--train_file\",\"/opt/ml/input/data/train/train.csv\",\"--transformer_layer_cls_to_wrap\",\"LlamaDecoderLayer\",\"--validation_file\",\"/opt/ml/input/data/valid/val.csv\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_CHANNEL_VALID=/opt/ml/input/data/valid\n",
      "SM_HP_ACCESS_TOKEN=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\n",
      "SM_HP_BLOCK_SIZE=4096\n",
      "SM_HP_CACHE_DIR=/opt/ml/sagemaker/warmpoolcache\n",
      "SM_HP_LEARNING_RATE=0.0002\n",
      "SM_HP_MODEL_DIR=/opt/ml/model\n",
      "SM_HP_MODEL_NAME_OR_PATH=meta-llama/Llama-2-70b-hf\n",
      "SM_HP_NUM_TRAIN_EPOCHS=1\n",
      "SM_HP_PER_DEVICE_EVAL_BATCH_SIZE=1\n",
      "SM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\n",
      "SM_HP_TRAIN_FILE=/opt/ml/input/data/train/train.csv\n",
      "SM_HP_TRANSFORMER_LAYER_CLS_TO_WRAP=LlamaDecoderLayer\n",
      "SM_HP_VALIDATION_FILE=/opt/ml/input/data/valid/val.csv\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "torchrun --nnodes 2 --nproc_per_node 8 --master_addr algo-2 --master_port 7777 --node_rank 1 train_fsdp.py --access_token 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 --block_size 4096 --cache_dir /opt/ml/sagemaker/warmpoolcache --learning_rate 0.0002 --model_dir /opt/ml/model --model_name_or_path meta-llama/Llama-2-70b-hf --num_train_epochs 1 --per_device_eval_batch_size 1 --per_device_train_batch_size 1 --train_file /opt/ml/input/data/train/train.csv --transformer_layer_cls_to_wrap LlamaDecoderLayer --validation_file /opt/ml/input/data/valid/val.csv\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError:\n",
      "Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError:\n",
      "Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError\n",
      ": cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "raise RuntimeError(\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError:\n",
      "Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError\n",
      ": Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "raise RuntimeError(\n",
      "RuntimeError:\n",
      "Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError:\n",
      "Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError\n",
      ": cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError\n",
      ": Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError:\n",
      "Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "raise RuntimeError(from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "RuntimeError\n",
      ": ImportErrorFailed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py): cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      "    from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "return importlib.import_module(\".\" + module_name, self.__name__)value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      "from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      "ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "The above exception was the direct cause of the following exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      "from transformers import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      "value = getattr(module, name)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      "module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      "raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n",
      "cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 89) of binary: /opt/conda/bin/python\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 88) of binary: /opt/conda/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/torchrun\", line 33, in <module>\n",
      "sys.exit(load_entry_point('torch==2.0.1', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      "return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 794, in main\n",
      "run(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\n",
      "elastic_launch(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "return launch_agent(self._config, self._entrypoint, list(args))\n",
      "File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n",
      "raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors\n",
      ".ChildFailedError: \n",
      "============================================================\n",
      "train_fsdp.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 9 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 89)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 10 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 90)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[3]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 11 (local_rank: 3)\n",
      "  exitcode  : 1 (pid: 91)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[4]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 12 (local_rank: 4)\n",
      "  exitcode  : 1 (pid: 92)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[5]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 13 (local_rank: 5)\n",
      "  exitcode  : 1 (pid: 93)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[6]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 14 (local_rank: 6)\n",
      "  exitcode  : 1 (pid: 94)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[7]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 15 (local_rank: 7)\n",
      "  exitcode  : 1 (pid: 95)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-10-03_20:20:56\n",
      "  host      : algo-1\n",
      "  rank      : 8 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 88)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/torchrun\", line 33, in <module>\n",
      "sys.exit(load_entry_point('torch==2.0.1', 'console_scripts', 'torchrun')())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      "return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 794, in main\n",
      "run(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\n",
      "elastic_launch(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n",
      "raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train_fsdp.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 90)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 91)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[3]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 1 (pid: 92)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[4]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 4 (local_rank: 4)\n",
      "  exitcode  : 1 (pid: 93)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[5]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 5 (local_rank: 5)\n",
      "  exitcode  : 1 (pid: 94)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[6]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 6 (local_rank: 6)\n",
      "  exitcode  : 1 (pid: 95)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[7]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 7 (local_rank: 7)\n",
      "  exitcode  : 1 (pid: 96)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-10-03_20:20:51\n",
      "  host      : algo-2\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 89)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "2023-10-03 20:20:56,927 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-10-03 20:20:56,927 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\n",
      "2023-10-03 20:20:56,928 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n",
      "2023-10-03 20:20:56,928 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "ExitCode 1\n",
      "ErrorMessage \"ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      " \n",
      " The above exception was the direct cause of the following exception\n",
      " Traceback (most recent call last)\n",
      " File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      " from transformers import (\n",
      " File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      " value = getattr(module, name)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      " module = self._get_module(self._class_to_module[name])\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      " raise RuntimeError(\n",
      " RuntimeError\n",
      " Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback)\n",
      " cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      " return importlib.import_module(\".\" + module_name, self.__name__)\n",
      " File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      " return _bootstrap._gcd_import(name[level:], package, level)\n",
      " File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      " File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      " File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      " File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      " File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      " File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      " from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      " ImportError\n",
      " RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback)\n",
      " ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 89) of binary: /opt/conda/bin/python\n",
      " File \"/opt/conda/bin/torchrun\", line 33, in <module>\n",
      " sys.exit(load_entry_point('torch==2.0.1', 'console_scripts', 'torchrun')())\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      " return f(*args, **kwargs)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 794, in main\n",
      " run(args)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\n",
      " elastic_launch(\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      " return launch_agent(self._config, self._entrypoint, list(args))\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n",
      " raise ChildFailedError(\n",
      " torch.distributed.elastic.multiprocessing.errors.ChildFailedError\n",
      " ============================================================\n",
      " train_fsdp.py FAILED\n",
      " ------------------------------------------------------------\n",
      " Failures\n",
      " [1]\n",
      " time      : 2023-10-03_20:20:51\n",
      " host      : algo-2\n",
      " rank      : 1 (local_rank: 1)\n",
      " exitcode  : 1 (pid: 90)\n",
      " error_file: <N/A>\n",
      " traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      " [2]\n",
      " rank      : 2 (local_rank: 2)\n",
      " exitcode  : 1 (pid: 91)\n",
      " [3]\n",
      " rank      : 3 (local_rank: 3)\n",
      " exitcode  : 1 (pid: 92)\n",
      " [4]\n",
      " rank      : 4 (local_rank: 4)\n",
      " exitcode  : 1 (pid: 93)\n",
      " [5]\n",
      " rank      : 5 (local_rank: 5)\n",
      " exitcode  : 1 (pid: 94)\n",
      " [6]\n",
      " rank      : 6 (local_rank: 6)\n",
      " exitcode  : 1 (pid: 95)\n",
      " [7]\n",
      " rank      : 7 (local_rank: 7)\n",
      " exitcode  : 1 (pid: 96)\n",
      " Root Cause (first observed failure)\n",
      " [0]\n",
      " rank      : 0 (local_rank: 0)\n",
      " exitcode  : 1 (pid: 89)\"\n",
      "Command \"torchrun --nnodes 2 --nproc_per_node 8 --master_addr algo-2 --master_port 7777 --node_rank 0 train_fsdp.py --access_token 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 --block_size 4096 --cache_dir /opt/ml/sagemaker/warmpoolcache --learning_rate 0.0002 --model_dir /opt/ml/model --model_name_or_path meta-llama/Llama-2-70b-hf --num_train_epochs 1 --per_device_eval_batch_size 1 --per_device_train_batch_size 1 --train_file /opt/ml/input/data/train/train.csv --transformer_layer_cls_to_wrap LlamaDecoderLayer --validation_file /opt/ml/input/data/valid/val.csv\"\n",
      "2023-10-03 20:20:56,928 sagemaker-training-toolkit ERROR    Encountered exit_code 1\n",
      "2023-10-03 20:20:56,903 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2023-10-03 20:20:56,903 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\n",
      "2023-10-03 20:20:56,903 sagemaker-training-toolkit ERROR    Reporting training FAILURE\n",
      "2023-10-03 20:20:56,903 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "ExitCode 1\n",
      "ErrorMessage \"ImportError\n",
      " cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      " \n",
      " The above exception was the direct cause of the following exception\n",
      " Traceback (most recent call last)\n",
      " File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n",
      " from transformers import (\n",
      " File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n",
      " value = getattr(module, name)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n",
      " module = self._get_module(self._class_to_module[name])\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n",
      " raise RuntimeError(\n",
      " RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1282, in _get_module\n",
      " return importlib.import_module(\".\" + module_name, self.__name__)\n",
      " File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      " return _bootstrap._gcd_import(name[level:], package, level)\n",
      " File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      " File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      " File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      " File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      " File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      " File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      " File \"/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 45, in <module>\n",
      " from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      " ImportError: cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      " RuntimeError\n",
      " Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback)\n",
      " raise RuntimeError(from flash_attn import flash_attn_func, flash_attn_varlen_func\n",
      " ImportErrorFailed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback)\n",
      " cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py): cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n",
      " return importlib.import_module(\".\" + module_name, self.__name__)value = getattr(module, name)\n",
      " ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 88) of binary: /opt/conda/bin/python\n",
      " File \"/opt/conda/bin/torchrun\", line 33, in <module>\n",
      " sys.exit(load_entry_point('torch==2.0.1', 'console_scripts', 'torchrun')())\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      " return f(*args, **kwargs)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 794, in main\n",
      " run(args)\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\n",
      " elastic_launch(\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      " return launch_agent(self._config, self._entrypoint, list(args))\n",
      " File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n",
      " raise ChildFailedError(\n",
      " torch.distributed.elastic.multiprocessing.errors\n",
      " .ChildFailedError\n",
      " ============================================================\n",
      " train_fsdp.py FAILED\n",
      " ------------------------------------------------------------\n",
      " Failures\n",
      " [1]\n",
      " time      : 2023-10-03_20:20:56\n",
      " host      : algo-1\n",
      " rank      : 9 (local_rank: 1)\n",
      " exitcode  : 1 (pid: 89)\n",
      " error_file: <N/A>\n",
      " traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      " [2]\n",
      " rank      : 10 (local_rank: 2)\n",
      " exitcode  : 1 (pid: 90)\n",
      " [3]\n",
      " rank      : 11 (local_rank: 3)\n",
      " exitcode  : 1 (pid: 91)\n",
      " [4]\n",
      " rank      : 12 (local_rank: 4)\n",
      " exitcode  : 1 (pid: 92)\n",
      " [5]\n",
      " rank      : 13 (local_rank: 5)\n",
      " exitcode  : 1 (pid: 93)\n",
      " [6]\n",
      " rank      : 14 (local_rank: 6)\n",
      " exitcode  : 1 (pid: 94)\n",
      " [7]\n",
      " rank      : 15 (local_rank: 7)\n",
      " exitcode  : 1 (pid: 95)\n",
      " Root Cause (first observed failure)\n",
      " [0]\n",
      " rank      : 8 (local_rank: 0)\n",
      " exitcode  : 1 (pid: 88)\"\n",
      "Command \"torchrun --nnodes 2 --nproc_per_node 8 --master_addr algo-2 --master_port 7777 --node_rank 1 train_fsdp.py --access_token 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 --block_size 4096 --cache_dir /opt/ml/sagemaker/warmpoolcache --learning_rate 0.0002 --model_dir /opt/ml/model --model_name_or_path meta-llama/Llama-2-70b-hf --num_train_epochs 1 --per_device_eval_batch_size 1 --per_device_train_batch_size 1 --train_file /opt/ml/input/data/train/train.csv --transformer_layer_cls_to_wrap LlamaDecoderLayer --validation_file /opt/ml/input/data/valid/val.csv\"\n",
      "2023-10-03 20:20:56,903 sagemaker-training-toolkit ERROR    Encountered exit_code 1\n",
      "\n",
      "2023-10-03 20:21:19 Uploading - Uploading generated training model\n",
      "2023-10-03 20:21:19 Failed - Resource retained for reuse\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job falcon-instruction-fine-tuning-2023-10-03-20-09-40-599: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ImportError\n cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n \n The above exception was the direct cause of the following exception\n Traceback (most recent call last)\n File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n from transformers import (\n File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n value = getattr(module, name)\n File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n module = self._get_module(self._class_to_module[name])\n File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n raise RuntimeError(\n RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its trac",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m estimator\u001b[39m.\u001b[39;49mfit({\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m:train_data_url,\u001b[39m\"\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m\"\u001b[39;49m:valid_data_url})\n",
      "File \u001b[0;32m~/Documents/projects/pathways/.conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m run_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/pathways/.conda/lib/python3.10/site-packages/sagemaker/estimator.py:1314\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjobs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1313\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 1314\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlatest_training_job\u001b[39m.\u001b[39;49mwait(logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/Documents/projects/pathways/.conda/lib/python3.10/site-packages/sagemaker/estimator.py:2597\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[39m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2597\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mlogs_for_job(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjob_name, wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, log_type\u001b[39m=\u001b[39;49mlogs)\n\u001b[1;32m   2598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2599\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mwait_for_job(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/Documents/projects/pathways/.conda/lib/python3.10/site-packages/sagemaker/session.py:4963\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   4942\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlogs_for_job\u001b[39m(\u001b[39mself\u001b[39m, job_name, wait\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, poll\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, log_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll\u001b[39m\u001b[39m\"\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   4943\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   4944\u001b[0m \n\u001b[1;32m   4945\u001b[0m \u001b[39m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4961\u001b[0m \u001b[39m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   4962\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4963\u001b[0m     _logs_for_job(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboto_session, job_name, wait, poll, log_type, timeout)\n",
      "File \u001b[0;32m~/Documents/projects/pathways/.conda/lib/python3.10/site-packages/sagemaker/session.py:6887\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(boto_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   6884\u001b[0m             last_profiler_rule_statuses \u001b[39m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   6886\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m-> 6887\u001b[0m     _check_job_status(job_name, description, \u001b[39m\"\u001b[39;49m\u001b[39mTrainingJobStatus\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   6888\u001b[0m     \u001b[39mif\u001b[39;00m dot:\n\u001b[1;32m   6889\u001b[0m         \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/projects/pathways/.conda/lib/python3.10/site-packages/sagemaker/session.py:6940\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mCapacityError\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(reason):\n\u001b[1;32m   6935\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mCapacityError(\n\u001b[1;32m   6936\u001b[0m         message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   6937\u001b[0m         allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mCompleted\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStopped\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   6938\u001b[0m         actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   6939\u001b[0m     )\n\u001b[0;32m-> 6940\u001b[0m \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6941\u001b[0m     message\u001b[39m=\u001b[39mmessage,\n\u001b[1;32m   6942\u001b[0m     allowed_statuses\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mCompleted\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStopped\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   6943\u001b[0m     actual_status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m   6944\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job falcon-instruction-fine-tuning-2023-10-03-20-09-40-599: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"ImportError\n cannot import name 'flash_attn_func' from 'flash_attn' (/opt/conda/lib/python3.10/site-packages/flash_attn/__init__.py)\n \n The above exception was the direct cause of the following exception\n Traceback (most recent call last)\n File \"/opt/ml/code/train_fsdp.py\", line 7, in <module>\n from transformers import (\n File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1273, in __getattr__\n value = getattr(module, name)\n File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1272, in __getattr__\n module = self._get_module(self._class_to_module[name])\n File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1284, in _get_module\n raise RuntimeError(\n RuntimeError: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its trac"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"train\":train_data_url,\"valid\":valid_data_url})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the warmpool if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.update_training_job(estimator.latest_training_job.job_name, resource_config={\"KeepAlivePeriodInSeconds\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
